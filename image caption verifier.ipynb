{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# Download caption annotation files\n",
    "annotation_folder = '/annotations/'\n",
    "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
    "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
    "                                           extract=True)\n",
    "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
    "  os.remove(annotation_zip)\n",
    "\n",
    "# Download image files\n",
    "image_folder = '/train2014/'\n",
    "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
    "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='http://images.cocodataset.org/zips/train2014.zip',\n",
    "                                      extract=True)\n",
    "  PATH = os.path.dirname(image_zip) + image_folder\n",
    "  os.remove(image_zip)\n",
    "else:\n",
    "  PATH = os.path.abspath('.') + image_folder\n",
    "'''\n",
    "!pip install pycocotools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "dataDir='../input/coco-2017-dataset/coco2017/'\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "coco=COCO(annFile)\n",
    "\n",
    "capFile='{}/annotations/captions_{}.json'.format(dataDir,dataType)\n",
    "coco_caps = COCO(capFile)\n",
    "ids = list(coco.anns.keys())\n",
    " \n",
    "import pandas as pd\n",
    "data_dict = {}\n",
    "for item in coco.dataset['images']:\n",
    "        data_dict[item['id']] = item['file_name'] \n",
    "\n",
    "caps_list = list(coco_caps.anns.values())\n",
    "\n",
    "cap_dict = {}\n",
    "for item in caps_list:\n",
    "        try:\n",
    "            cap_dict[item['image_id']].append(item['caption'])\n",
    "        except:\n",
    "            cap_dict[item['image_id']] = [item['caption']]\n",
    "    \n",
    "cap_df = pd.DataFrame(cap_dict.items(), columns=['image_id', 'caption'])\n",
    "image_df = pd.DataFrame(data_dict.items(), columns=['image_id', 'file_name'])\n",
    "data_df = pd.merge(cap_df, image_df, on=\"image_id\")\n",
    "data_df = data_df.iloc[:6000, :]\n",
    "data_df\n",
    "len(data_df.index)\n",
    "#creating dataframe from coco \n",
    "import pandas as pd\n",
    "\n",
    "def create_df_from_coco(coco, coco_caps):\n",
    "    \n",
    "    data_dict = {}\n",
    "    for item in coco.dataset['images']:\n",
    "        data_dict[item['id']] = item['file_name'] \n",
    "        \n",
    "        \n",
    "    caps_list = list(coco_caps.anns.values())  \n",
    "    cap_dict = {}\n",
    "    for item in caps_list:\n",
    "        try:\n",
    "            cap_dict[item['image_id']].append(item['caption'])\n",
    "        except:\n",
    "            cap_dict[item['image_id']] = [item['caption']]\n",
    "    \n",
    "    cap_df = pd.DataFrame(cap_dict.items(), columns=['image_id', 'caption'])\n",
    "    image_df = pd.DataFrame(data_dict.items(), columns=['image_id', 'file_name'])\n",
    "    data_df = pd.merge(cap_df, image_df, on=\"image_id\")\n",
    "    data_df = data_df = data_df.iloc[:6000, :]\n",
    "    \n",
    "    print(len(cap_df), len(image_df), len(data_df))\n",
    "    train_captions = []\n",
    "    img_name_vector = []\n",
    "    caption_labels = []\n",
    "    img_path_list = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for ind in data_df.index:\n",
    "        image_path =  '../input/coco-2017-dataset/coco2017/train2017/' + data_df['file_name'][ind]\n",
    "        #print(data_df['caption'][ind], data_df['file_name'][ind])\n",
    "        caption_list = data_df['caption'][ind]\n",
    "        train_captions.extend(caption_list)\n",
    "        img_name_vector.extend([image_path] * len(caption_list))\n",
    "        caption_labels.extend([1 for i in range(len(caption_list))]) \n",
    "        \n",
    "        img_path_list.extend([image_path])\n",
    "        \n",
    "        \n",
    "    #get negative samples\n",
    "    for ind in data_df.index[4000:6000]:\n",
    "        image_path =  '../input/coco-2017-dataset/coco2017/train2017/' + data_df['file_name'][ind]\n",
    "        #print(data_df['caption'][ind], data_df['file_name'][ind])\n",
    "        random_set = np.random.randint(4000, size=5)\n",
    "        caption_list = [data_df['caption'][i][0] for i in random_set]\n",
    "       \n",
    "        train_captions.extend(caption_list)\n",
    "        img_name_vector.extend([image_path] * len(caption_list))\n",
    "        caption_labels.extend([0 for i in range(len(caption_list))]) \n",
    "        \n",
    "    train_data_df = pd.DataFrame(list(zip(img_name_vector, train_captions, caption_labels)),\n",
    "               columns =['Image', 'Caption', 'Label'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_data_df, img_path_list\n",
    "    \n",
    "train_data_df, img_path_list = create_df_from_coco(coco, coco_caps)\n",
    "train_data_df\n",
    "s = set(img_path_list)\n",
    "len(s)\n",
    "from PIL import Image\n",
    "#print(train_data_df['Caption'][601749])\n",
    "#Image.open(train_data_df['Image'][601749])\n",
    "import re\n",
    "train_data_df['Caption'] = train_data_df['Caption'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "train_data_df\n",
    "#make all lower case\n",
    "train_data_df['Caption'] = train_data_df['Caption'].str.lower()\n",
    "train_data_df = train_data_df.reset_index(drop=True)\n",
    "train_data_df\n",
    "from nltk import word_tokenize\n",
    "train_data_df['Caption'] = train_data_df.apply(lambda row: word_tokenize(row['Caption']), axis=1)\n",
    "\n",
    "train_data_df\n",
    "df = train_data_df\n",
    "a = list(df['Caption'].str.len())\n",
    "print('max :', max(a))\n",
    "print('avg :', sum(a)/len(a))\n",
    "# Import data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(a , color=\"green\", bins=20)\n",
    "plt.xlabel('Len of caption', fontsize=16)\n",
    "plt.xlim(0,40)\n",
    "#change the values later\n",
    "max_c_len = 20\n",
    "#train tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(train_data_df['Caption'])\n",
    "voc_size = len(x_tokenizer.word_index) + 1\n",
    "voc_size\n",
    "################################testing\n",
    "\n",
    "f = open('../input/glove-embeddings/glove.6B.300d.txt', 'r')\n",
    "lines = f.readlines()\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "words_list = []\n",
    "glove_emb = {}\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.strip('\\n')\n",
    "    tokens = line.split()\n",
    "    temp = list(map(float, tokens[1:]))\n",
    "    word = tokens[0].lower()\n",
    "    words_list.append(word)\n",
    "    glove_emb[word] = np.array(temp)\n",
    "    #print(len(temp))\n",
    "\n",
    "\n",
    "num_tokens = len(x_tokenizer.word_index) + 1\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "m = []\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in x_tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = glove_emb[word]\n",
    "    \n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    except:\n",
    "        misses += 1\n",
    "        m.append(word)\n",
    "        #print(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "################################testing ended\n",
    "#creating embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_emb_c = x_tokenizer.texts_to_sequences(train_data_df['Caption']) \n",
    "# making all instances same length\n",
    "train_emb_c = pad_sequences(train_emb_c,  maxlen=max_c_len, padding='post')\n",
    " \n",
    "#image classifieser\n",
    "from keras import backend as K \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed,Attention\n",
    "from tensorflow.keras.models import Model,load_model, model_from_json\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
    "K.clear_session() \n",
    "latent_dim = 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#context lstm\n",
    " \n",
    "context_inputs = Input(shape=(max_c_len,)) \n",
    "contxt_emb = Embedding(voc_size, latent_dim, weights=[embedding_matrix],trainable=True)(context_inputs) \n",
    "#LSTM 1 \n",
    "context_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output1, context_state_h1, context_state_c1 = context_lstm1(contxt_emb) \n",
    "\n",
    "\n",
    "#LSTM 2 \n",
    "context_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output, context_state_h, context_state_c = context_lstm2(context_output1)\n",
    "\n",
    "'''\n",
    "#LSTM 3 \n",
    "context_lstm3 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output, context_state_h, context_state_c = context_lstm3(context_output2)\n",
    "'''\n",
    "\n",
    "predictions = Dense(1, activation=\"sigmoid\", name=\"predictions\")(context_output)\n",
    "\n",
    "model = Model(context_inputs, predictions) \n",
    "plot_model(model, to_file='train_model.png', show_shapes=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( train_emb_c, train_data_df['Label'], test_size=0.2, random_state=42)\n",
    " \n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(X_train,y_train, epochs=3)\n",
    " \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# InceptionV3 model trained on imagenet data\n",
    "model = InceptionV3(weights='imagenet')\n",
    "# Remove the last layer \n",
    "model_new = Model(model.input, model.layers[-2].output)\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input \n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def preprocess(image_path):\n",
    "    img = image.load_img(image_path, target_size=(299, 299))\n",
    " \n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    " \n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "# Function to encode a given image into a vector of size (2048, )\n",
    "def encode(image):\n",
    "    image = preprocess(image) \n",
    "    fea_vec = model_new.predict(image) \n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) \n",
    "    return fea_vec\n",
    "# Call the funtion to encode all the train images\n",
    "# This will take a while on CPU - Execute this only once\n",
    "img = '../input/coco2014/train2014/train2014/COCO_train2014_000000000009.jpg'\n",
    "encoding_train = {}\n",
    "\n",
    "encoding_train[img] = encode(img)\n",
    "encoding_train[img]\n",
    "from tqdm import tqdm\n",
    "encoding_train = {}\n",
    "for img in tqdm(img_path_list):\n",
    "    encoding_train[img] = encode(img)\n",
    "    \n",
    "\n",
    "#arr = os.listdir('../input/coco2014/train2014/train2014/')\n",
    "#arr\n",
    "import pickle\n",
    "# Save the bottleneck train features to disk\n",
    "with open(\"encoded_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    pickle.dump(encoding_train, encoded_pickle)\n",
    "train_features = pickle.load(open(\"encoded_images.pkl\", \"rb\"))\n",
    " \n",
    "#image classifieser\n",
    "from keras import backend as K \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed,Attention, Dropout\n",
    "from tensorflow.keras.models import Model,load_model, model_from_json\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers.merge import add\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
    "K.clear_session() \n",
    "latent_dim = 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#context lstm\n",
    " \n",
    "context_inputs = Input(shape=(max_c_len,)) \n",
    "contxt_emb = Embedding(voc_size, latent_dim, weights=[embedding_matrix],trainable=True)(context_inputs) \n",
    "#LSTM 1 \n",
    "context_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output1, context_state_h1, context_state_c1 = context_lstm1(contxt_emb) \n",
    "\n",
    "\n",
    "#LSTM 2 \n",
    "context_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output, context_state_h, context_state_c = context_lstm2(context_output1)\n",
    "\n",
    "'''\n",
    "#LSTM 3 \n",
    "context_lstm3 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "context_output, context_state_h, context_state_c = context_lstm3(context_output2)\n",
    "'''\n",
    "\n",
    "# image embedding\n",
    "image_inputs = Input(shape=(2048,))\n",
    "image_dropout = Dropout(0.5)(image_inputs)\n",
    "image_outputs = Dense(latent_dim, activation='relu')(image_dropout)\n",
    "\n",
    "\n",
    "\n",
    "decoder_concat_input = add([context_output, image_outputs])\n",
    "\n",
    "predictions = Dense(1, activation=\"sigmoid\", name=\"predictions\")(decoder_concat_input)\n",
    "\n",
    "model = Model([context_inputs, image_inputs], predictions) \n",
    "plot_model(model, to_file='train_model.png', show_shapes=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( train_emb_c, train_data_df['Label'], test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
